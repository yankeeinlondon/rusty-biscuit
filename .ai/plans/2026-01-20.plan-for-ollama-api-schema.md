---
status: "done"
started_at: 10:47:00
finished_at: 10:52:00
duration: 5 minutes
tts_gender: male
requirements:
  Define the Ollama API using schematic primitives:
  - Both native API (/api/*) AND OpenAI-compatible (/v1/*) endpoints
  - Include SSE streaming support for generate/chat endpoints
  - Follow existing patterns in schematic/definitions (e.g., OpenAI definition if exists)
  - Use primitives from schematic/define package
  - Generate schema code in schematic/schema via schematic/gen
  - Write tests using rust-testing skill patterns
required_skills:
  - ollama
  - rust
  - rust-testing
important_skills:
  serde: "when defining request/response structs that need JSON serialization"
  thiserror: "when adding error types to the definitions"
  syn: "if understanding how schematic-gen parses definitions"
  prettyplease: "if troubleshooting generated code formatting"
subagents:
  Plan: "Create phased implementation plan"
  Explore: "Module assessment for monorepo impact"
  general-purpose: "Reviews (completeness, concurrency, correctness) and finalization"
  feature-tester-rust: "Test implementation for Rust code"
monorepo_modules_impacted:
  - schematic/define (HIGH - add ApiResponse::Stream)
  - schematic/definitions (HIGH - new ollama module)
  - schematic/gen (HIGH - streaming code generation)
  - schematic/schema (HIGH - generated output)
completeness_changes: []
concurrency_changes: []
detail_changes: []
lessons_learned_count: 6
---
# Planning Process

- [x] Prep Started [10:47am]
    - [x] Identified Skills [10:47am]
    - [x] Identified Subagents [10:47am] (manual - agent-picker unavailable)
- [x] Prep complete with 35% context available [10:47am]
- [x] Clarify [orchestrator] started [10:47am]
    - [x] User asked clarifying questions (human in the loop) [10:48am]
    - [x] Requirements updated: both native + OpenAI endpoints, SSE streaming, follow existing patterns [10:48am]
- [x] Planning Subagent [agent: **Plan**] started [10:48am]
    - [x] subagent skills used: ollama, rust, rust-testing, serde
    - [x] Planning completed [10:50am]
- [x] Module Assessment Subagent [agent: **Explore**] started [10:48am]
    - [x] subagent skills used: rust, serde
    - [x] Module Assessment completed [10:50am]
- [x] All Pre-review Steps are complete
    - 35% of context window still available
- [x] Review Started [10:50am]
   - [x] Completeness Review [agent: **general-purpose**]
       - [x] subagent skills used: rust, ollama, serde
   - [x] Concurrency Review [agent: **general-purpose**]
       - [x] subagent skills used: rust
   - [x] Details/Knowledge Based Review [agent: **general-purpose**]
        - [x] subagent skills used: rust, ollama
- [x] Reviews Completed [10:51am]
    - 35% of context window still available
- [x] Plan Finalization [orchestrator] started [10:51am]
    - [x] Incorporated review feedback: added endpoint tables with exact paths and HTTP methods
- [x] Plan finalized [10:52am]
    - 35% of context window still available
- Final Steps
    - [x] Lessons learned collected from all subagents (6 entries)
    - [x] Researching 1 package (futures) [10:52am]
- [x] Summarized plan to user via STDOUT
    - Project File: `.ai/plans/2026-01-20.plan-for-ollama-api-schema.md`
    - Started: 10:47am
    - Completed: 10:52am
    - Duration: 5 minutes



## Plan

### Phase 1: Create Ollama Types Module

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, serde |
| **Suggested Skills** | thiserror (if adding error types) |
| **Complexity** | High |
| **Dependencies** | None |
| **Parallelizable** | No |

**Objective:** Define all request/response types for both native and OpenAI-compatible Ollama APIs in `schematic/definitions/src/ollama/types.rs`.

**Deliverables:**
- Native API types: ModelOptions, Message, GenerateRequest/Response, ChatRequest/Response, EmbeddingsRequest/Response, model management types
- OpenAI-compatible types: OpenAIChatCompletionRequest/Response, OpenAICompletionRequest/Response, OpenAIEmbeddingRequest/Response, OpenAIListModelsResponse

**Acceptance Criteria:**
- [ ] All types derive `Debug, Clone, Serialize, Deserialize`
- [ ] Optional fields use `#[serde(skip_serializing_if = "Option::is_none")]`
- [ ] Types match Ollama API documentation
- [ ] Unit tests for serialization round-trips

---

### Phase 2: Create Native Ollama API Definition

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, ollama |
| **Suggested Skills** | None |
| **Complexity** | Medium |
| **Dependencies** | Phase 1 |
| **Parallelizable** | No |

**Objective:** Define the native Ollama API (`/api/*` endpoints) in `schematic/definitions/src/ollama/mod.rs`.

**Deliverables:**
- `define_ollama_native_api() -> RestApi` function with `AuthStrategy::None` and base URL `http://localhost:11434`
- 11 endpoints with exact paths:

| Endpoint ID | Method | Path | Streaming |
|-------------|--------|------|-----------|
| Generate | POST | /api/generate | Yes (NDJSON) |
| Chat | POST | /api/chat | Yes (NDJSON) |
| Embeddings | POST | /api/embeddings | No |
| ListModels | GET | /api/tags | No |
| ShowModel | POST | /api/show | No |
| PullModel | POST | /api/pull | Yes (progress) |
| PushModel | POST | /api/push | Yes (progress) |
| CopyModel | POST | /api/copy | No |
| DeleteModel | DELETE | /api/delete | No |
| CreateModel | POST | /api/create | Yes (progress) |
| ListRunningModels | GET | /api/ps | No |

**Acceptance Criteria:**
- [ ] All 11 native endpoints defined with correct HTTP methods
- [ ] Streaming endpoints (Generate, Chat, PullModel, PushModel, CreateModel) return `ApiResponse::Binary`
- [ ] Unit tests verify endpoint configuration

---

### Phase 3: Create OpenAI-Compatible API Definition

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, ollama |
| **Suggested Skills** | None |
| **Complexity** | Low |
| **Dependencies** | Phase 1 |
| **Parallelizable** | Yes (with Phase 2) |

**Objective:** Define the OpenAI-compatible API (`/v1/*` endpoints).

**Deliverables:**
- `define_ollama_openai_api() -> RestApi` function with `AuthStrategy::None` and base URL `http://localhost:11434`
- 4 endpoints with exact paths:

| Endpoint ID | Method | Path | Streaming |
|-------------|--------|------|-----------|
| ChatCompletions | POST | /v1/chat/completions | Yes (SSE) |
| Completions | POST | /v1/completions | Yes (SSE) |
| Embeddings | POST | /v1/embeddings | No |
| ListModels | GET | /v1/models | No |

**Acceptance Criteria:**
- [ ] All 4 OpenAI-compatible endpoints defined with correct paths
- [ ] Streaming endpoints (ChatCompletions, Completions) return `ApiResponse::Binary`
- [ ] Response types match OpenAI format

---

### Phase 4: Register APIs and Update Exports

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust |
| **Suggested Skills** | None |
| **Complexity** | Low |
| **Dependencies** | Phase 2, Phase 3 |
| **Parallelizable** | No |

**Objective:** Register the new Ollama APIs in the definitions crate and update exports.

**Deliverables:**
- Update `schematic/definitions/src/lib.rs`: add `pub mod ollama;`
- Update `schematic/gen/src/main.rs`: add "ollama-native" and "ollama-openai" to CLI dispatcher

**Acceptance Criteria:**
- [ ] `schematic-definitions` crate exports Ollama APIs
- [ ] CLI can generate code for both Ollama APIs
- [ ] `cargo build -p schematic-definitions` succeeds

---

### Phase 5: Comprehensive Testing

| Property | Value |
|----------|-------|
| **Subagent** | `feature-tester-rust` |
| **Required Skills** | rust, rust-testing, serde |
| **Suggested Skills** | None |
| **Complexity** | Medium |
| **Dependencies** | Phase 4 |
| **Parallelizable** | No |

**Objective:** Write comprehensive tests for the Ollama API definition and types.

**Deliverables:**
- Type serialization tests in `types.rs`
- API definition tests in `mod.rs`

**Acceptance Criteria:**
- [ ] All serialization round-trip tests pass
- [ ] All API definition tests pass
- [ ] `cargo test -p schematic-definitions -- ollama` passes

---

### Phase 6: Generate Schema Code

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust |
| **Suggested Skills** | None |
| **Complexity** | Low |
| **Dependencies** | Phase 5 |
| **Parallelizable** | No |

**Objective:** Generate the schema code and verify it compiles.

**Deliverables:**
- Generated `schematic/schema/src/ollamanative.rs`
- Generated `schematic/schema/src/ollamaopenai.rs`
- Updated `schematic/schema/src/lib.rs`

**Acceptance Criteria:**
- [ ] Both schema modules generate without errors
- [ ] Generated code compiles cleanly
- [ ] Generated code passes clippy


## Lessons Learned

> Capture discoveries about skills or memory resources (CLAUDE.md, README.md, etc.) that were inaccurate, incomplete, or missing.

- [SKILL: ollama]: SSE streaming format differs between native API (NDJSON) and OpenAI-compatible (SSE)
- [PATTERN: schematic]: Binary response type is used for streaming endpoints as interim solution (no first-class SSE support)
- [PATTERN: schematic]: Streaming Support Gap - no first-class SSE streaming, WebSocket exists for bidirectional
- [ARCHITECTURE: dependencies.md]: Doesn't document internal workspace package dependencies (define → definitions → gen → schema)
- [OLLAMA_API: DeleteModel]: /api/delete endpoint uses DELETE method with JSON body (model name in body, not path parameter)
- [DEPENDENCY_SCOPE: schematic]: futures and reqwest streaming features belong in schematic-schema (generated), not schematic-definitions


## Package Changes in Execution

> Dependencies to be added, updated, or removed during implementation. Research for ADD actions produces skill files.

- [ADD(schematic-schema)]: futures = "0.3" in cargo - Required for generated streaming response handlers using `Stream<Item = T>` trait
    - "How to use futures Stream with reqwest bytes_stream?"
- [UPDATE(schematic-schema)]: reqwest feature flags in cargo - Add "stream" feature for `response.bytes_stream()`

