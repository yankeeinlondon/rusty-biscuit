---
status: "done"
started_at: 12:43:00
finished_at: 12:55:00
duration: 12 minutes
tts_gender: male
requirements: |
  Refactor the biscuit-speaks package to remove the `tts` crate dependency and instead:
  1. Use InstalledTtsClients from the sniff library for host TTS discovery
  2. Add ElevenLabs cloud TTS support via schematic/schema API client
  3. Implement TTS prioritization based on OS with environment variable overrides
  4. Create the Speak struct with builder pattern API for async TTS operations
  5. Support volume, gender, language, and voice configuration
  6. Update all client packages (so-you-say, research/lib, research/cli)

  Clarified requirements:
  - API: Async-only (no blocking wrappers needed)
  - Failover: Auto-failover to next provider on failure
  - Detection: Lazy singleton pattern (detect once, cache globally)
required_skills:
  - rust
  - thiserror
  - tokio
  - serde
  - reqwest
  - strum
important_skills:
  anyhow: "For application-level error handling in client packages"
  color-eyre: "For enhanced error context in CLI applications"
  rust-testing: "When writing tests for TTS abstraction layer"
  monorepos: "When coordinating changes across workspace packages"
subagents:
  Plan: "Create phased implementation plan"
  Explore: "Module assessment for monorepo impact"
  general-purpose: "Reviews (completeness, concurrency, correctness) and finalization"
  feature-tester-rust: "Test implementation"
monorepo_modules_impacted:
  - biscuit-speaks (core refactor)
  - so-you-say (client update)
  - research/lib (client update)
  - research/cli (client update)
completeness_changes: []
concurrency_changes: []
detail_changes: []
lessons_learned_count: 0
---
# Planning Process

- [x] Prep Started [12:43pm]
    - [x] Identified Skills [12:44pm]
    - [x] Identified Subagents [12:44pm]
- [x] Prep complete with 35% context available [12:44pm]
- [x] Clarify (orchestrator) [12:45pm]
    - [x] User asked clarifying questions (human in the loop) [12:45pm]
    - [x] Requirements updated: async-only, auto-failover, lazy singleton [12:45pm]
- [x] Planning Subagent [agent: **Plan**] started [12:45pm]
    - [x] subagent skills used: rust, thiserror, tokio, serde, strum
    - [x] Planning completed [12:47pm]
- [x] Module Assessment Subagent [agent: **Explore**] started [12:45pm]
    - [x] subagent skills used: rust
    - [x] Module Assessment completed [12:47pm]
- [x] All Pre-review Steps are complete
    - 35% of context window is still available
- [x] Review Started [12:48pm]
   - [x] Completeness Review [agent: **general-purpose**]
       - [x] subagent skills used: rust, thiserror, tokio, serde, reqwest, strum
   - [x] Concurrency Review [agent: **general-purpose**]
       - [x] subagent skills used: rust, tokio
   - [x] Details/Knowledge Based Review [agent: **general-purpose**]
        - [x] subagent skills used: rust, tokio, thiserror
- [x] Reviews Completed [12:49pm]
    - 35% of context window is still available
- [x] Plan Finalization [agent: **general-purpose**] started [12:50pm]
    - [x] subagent skills used: rust, tokio, thiserror
- [x] Plan finalized [12:55pm]
    - 25% of context window is still available
- Final Steps
    - [x] Lessons learned collected from all subagents
    - [ ] Researching 5 packages (schematic-schema, tokio, tempfile, which, wiremock)
- [x] Summarized plan to user via STDOUT
    - Project File: 2026-01-21.plan-for-biscuit-speaks-tts-refactor.md
    - Started: 12:43pm
    - Completed: 12:55pm
    - Duration: 12 minutes



## Plan

### Execution Summary

**Optimized Critical Path:**
```
Stage 1: Phase 0 + Phase 1 (Validation + Types) [2-3 hrs]
  |
Stage 2: Phase 2 || Phase 6 (Detection + Playback in parallel) [3-4 hrs]
  |
Stage 3: Phase 3a,3b,3c || Phase 4 (Host providers + Cloud in parallel) [4-5 hrs]
  |
Stage 4: Phase 5 (Speak API) [2-3 hrs]
  |
Stage 5: Phase 7a || Phase 7b || Phase 7c (Client updates in parallel) [2-3 hrs]
  |
Stage 6: Phase 8 + Phase 9a (Cleanup + unit tests) [2-3 hrs]
  |
Stage 7: Phase 9b (Integration tests) [2-3 hrs]
```

**Estimated Total: 18-24 hours** (40-50% reduction from original 35-45 hour estimate)

---

### Phase 0: Pre-Implementation Validation

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust |
| **Suggested Skills** | tokio (for async validation patterns) |
| **Complexity** | Low |
| **Dependencies** | None |
| **Parallelizable** | No (must complete before all other phases) |

**Objective:** Validate all blocking issues and research unknowns before implementation begins.

**Deliverables:**
- Validation that `InstalledTtsClients` from sniff-lib provides required TTS detection data
- Research document for Windows SAPI integration approach (PowerShell vs COM)
- Confirmation of schematic-schema binary response handling for audio bytes
- Rust edition check for async trait support (determines async-trait dependency)

**Acceptance Criteria:**
- [ ] sniff-lib `TtsClient` enum maps correctly to `HostTtsProvider` variants
- [ ] Windows SAPI approach documented (recommend PowerShell `Add-Type` for simplicity)
- [ ] schematic-schema `ApiResponse::Binary` confirmed to return `Vec<u8>`
- [ ] Decision on async-trait: use native Rust 2024 `async fn` in traits if edition supports

**Code Pattern Fixes to Document:**
```rust
// macOS say: -v is for VOICE selection, NOT volume
// CORRECT usage:
if let Some(voice) = &config.requested_voice {
    cmd.arg("-v").arg(voice);
}
// macOS say has NO direct volume flag - document this limitation
```

---

### Phase 1: Core Type Definitions

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, thiserror, strum |
| **Suggested Skills** | serde (if serialization needed for config persistence) |
| **Complexity** | Medium |
| **Dependencies** | Phase 0 |
| **Parallelizable** | No (foundational - all phases depend on this) |

**Objective:** Define all core types, enums, error types, and traits for the TTS abstraction layer.

**Deliverables:**
- `TtsProvider` enum (unifying host + cloud providers)
- `TtsConfig` struct with builder pattern
- `TtsError` enum with comprehensive error variants
- `TtsExecutor` trait defining the async speak interface
- `TtsFailoverStrategy` enum for configurable failover behavior
- `AudioFormat` enum (WAV, MP3, PCM for different providers)

**File Structure:**
```
biscuit-speaks/src/
├── lib.rs           # Re-exports, module declarations
├── types.rs         # TtsProvider, TtsConfig, AudioFormat, TtsFailoverStrategy
├── errors.rs        # TtsError with thiserror derives
├── traits.rs        # TtsExecutor trait definition
├── speak.rs         # Speak struct (placeholder)
├── providers/       # Provider implementations (Phase 3-4)
│   ├── mod.rs
│   ├── host/
│   └── cloud/
└── playback/        # Audio playback utilities (Phase 6)
    └── mod.rs
```

**Acceptance Criteria:**
- [ ] All types derive appropriate traits (Debug, Clone, PartialEq where applicable)
- [ ] `TtsError` uses `#[non_exhaustive]` for future extensibility
- [ ] `TtsFailoverStrategy` includes: `FirstAvailable`, `PreferHost`, `PreferCloud`, `SpecificProvider(TtsProvider)`
- [ ] `cargo build -p biscuit-speaks` compiles without errors

**Key Type Definitions:**
```rust
/// Strategy for handling provider failures
#[derive(Debug, Clone, Default)]
pub enum TtsFailoverStrategy {
    /// Try providers in priority order until one succeeds
    #[default]
    FirstAvailable,
    /// Prefer host providers, fall back to cloud
    PreferHost,
    /// Prefer cloud providers, fall back to host
    PreferCloud,
    /// Use specific provider only, no failover
    SpecificProvider(TtsProvider),
}

/// All errors from failover attempts, preserving debug info
#[derive(Debug, thiserror::Error)]
#[error("All TTS providers failed")]
pub struct AllProvidersFailed {
    /// Errors from each attempted provider
    pub errors: Vec<(TtsProvider, TtsError)>,
}
```

---

### Phase 2: TTS Provider Detection & Stack Building

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio |
| **Suggested Skills** | strum (for enum iteration) |
| **Complexity** | Medium |
| **Dependencies** | Phase 1 |
| **Parallelizable** | Yes (with Phase 6) |

**Objective:** Implement provider detection using sniff-lib and build OS-specific provider stacks with environment variable overrides.

**Deliverables:**
- `detect_available_providers()` function using sniff-lib `InstalledTtsClients`
- `build_provider_stack()` function returning OS-prioritized provider list
- `TtsEnvironment` module for parsing `TTS_PROVIDER` and `ELEVENLABS_API_KEY` env vars
- Lazy singleton pattern using `OnceLock<Vec<TtsProvider>>` for cached detection
- Implementation of `HostTtsProvider::is_available()` (currently `todo!()`)

**Environment Variable Support:**
| Variable | Description | Example |
|----------|-------------|---------|
| `TTS_PROVIDER` | Override provider selection | `elevenlabs`, `say`, `espeak` |
| `ELEVENLABS_API_KEY` | ElevenLabs API key | `sk-...` |
| `ELEVEN_LABS_API_KEY` | Alternate ElevenLabs key | `sk-...` |

**Acceptance Criteria:**
- [ ] `HostTtsProvider::is_available()` correctly maps to sniff-lib `TtsClient` enum
- [ ] Provider stacks match OS defaults: macOS (Say first), Linux (ESpeak first), Windows (SAPI first)
- [ ] `TTS_PROVIDER` env var overrides default stack ordering
- [ ] Detection runs once and caches results in `OnceLock`
- [ ] Unit tests for stack building on each OS target

**Implementation Pattern:**
```rust
use std::sync::OnceLock;
use sniff_lib::programs::{InstalledTtsClients, TtsClient};

static DETECTED_PROVIDERS: OnceLock<Vec<TtsProvider>> = OnceLock::new();

pub fn get_available_providers() -> &'static [TtsProvider] {
    DETECTED_PROVIDERS.get_or_init(|| {
        let installed = InstalledTtsClients::detect();
        build_provider_stack(&installed)
    })
}

impl HostTtsProvider {
    pub fn is_available(&self, installed: &InstalledTtsClients) -> bool {
        match self {
            Self::Say => installed.say.is_some(),
            Self::ESpeak => installed.espeak.is_some() || installed.espeak_ng.is_some(),
            Self::Festival => installed.festival.is_some(),
            Self::SAPI => installed.sapi.is_some(),
            // ... other mappings
        }
    }
}
```

---

### Phase 3a: Simple Host TTS Providers

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio |
| **Suggested Skills** | None |
| **Complexity** | Medium |
| **Dependencies** | Phase 2 |
| **Parallelizable** | Yes (with Phase 3b, 3c, Phase 4) |

**Objective:** Implement simple host TTS providers that have straightforward CLI interfaces.

**Providers (5):**
- `Say` (macOS) - Direct text-to-speech via stdin
- `ESpeak` / `ESpeak-NG` (Linux/cross-platform) - Simple CLI with voice selection
- `Festival` (Linux) - Text-to-speech with festival script
- `Pico2Wave` (Linux) - SVOX Pico TTS engine
- `SpdSay` (Linux) - Speech Dispatcher client

**Deliverables:**
- `providers/host/say.rs` - macOS Say implementation
- `providers/host/espeak.rs` - eSpeak/eSpeak-NG implementation
- `providers/host/festival.rs` - Festival implementation
- `providers/host/pico2wave.rs` - SVOX Pico implementation
- `providers/host/spd_say.rs` - Speech Dispatcher implementation

**Critical Code Fixes:**

```rust
// providers/host/say.rs
// CORRECT: macOS say has NO volume flag, -v is for VOICE
pub async fn speak(&self, text: &str, config: &TtsConfig) -> Result<(), TtsError> {
    let mut cmd = tokio::process::Command::new("say");

    // Voice selection (NOT volume!)
    if let Some(voice) = &config.requested_voice {
        cmd.arg("-v").arg(voice);
    }

    // Use stdin for text input with explicit EOF
    cmd.stdin(Stdio::piped());
    cmd.stdout(Stdio::null());
    cmd.stderr(Stdio::piped());

    let mut child = cmd.spawn().map_err(|e| TtsError::ProcessSpawnFailed {
        provider: "say".into(),
        source: e,
    })?;

    // CRITICAL: Take ownership of stdin, write, then drop for EOF
    let mut stdin = child.stdin.take()
        .ok_or(TtsError::StdinPipeError { provider: "say".into() })?;
    tokio::io::AsyncWriteExt::write_all(&mut stdin, text.as_bytes()).await?;
    drop(stdin); // Explicit EOF signal - REQUIRED

    let output = child.wait_with_output().await?;
    // ... handle output
}
```

**Acceptance Criteria:**
- [ ] All 5 providers implement `TtsExecutor` trait
- [ ] macOS Say does NOT use -v for volume (voice only)
- [ ] All providers use explicit `drop(stdin)` for EOF signal
- [ ] Error messages include provider name for debugging
- [ ] Unit tests for each provider (mock process execution)

---

### Phase 3b: Medium Complexity Host TTS Providers

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio |
| **Suggested Skills** | reqwest (for Gtts HTTP calls) |
| **Complexity** | Medium |
| **Dependencies** | Phase 2 |
| **Parallelizable** | Yes (with Phase 3a, 3c, Phase 4) |

**Objective:** Implement host TTS providers that require additional configuration or model files.

**Providers (3):**
- `EchoGarden` - Requires model configuration
- `Sherpa` - Requires `SHERPA_MODEL` and `SHERPA_TOKENS` env vars
- `Gtts` - Google TTS CLI (requires network, but runs as CLI)

**Deliverables:**
- `providers/host/echogarden.rs` - EchoGarden implementation
- `providers/host/sherpa.rs` - Sherpa-ONNX implementation with env var validation
- `providers/host/gtts.rs` - Google TTS CLI implementation

**Sherpa Environment Validation:**
```rust
// providers/host/sherpa.rs
pub fn validate_sherpa_env() -> Result<SherpaConfig, TtsError> {
    let model = std::env::var("SHERPA_MODEL")
        .map_err(|_| TtsError::MissingEnvironment {
            provider: "sherpa".into(),
            variable: "SHERPA_MODEL".into(),
        })?;

    let tokens = std::env::var("SHERPA_TOKENS")
        .map_err(|_| TtsError::MissingEnvironment {
            provider: "sherpa".into(),
            variable: "SHERPA_TOKENS".into(),
        })?;

    // Validate files exist
    if !std::path::Path::new(&model).exists() {
        return Err(TtsError::ModelFileNotFound { path: model });
    }

    Ok(SherpaConfig { model, tokens })
}
```

**Acceptance Criteria:**
- [ ] All 3 providers implement `TtsExecutor` trait
- [ ] Sherpa validates env vars before attempting speech
- [ ] EchoGarden handles model discovery
- [ ] Gtts handles network errors gracefully
- [ ] Unit tests with mocked dependencies

---

### Phase 3c: Complex Host TTS Providers

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio |
| **Suggested Skills** | None |
| **Complexity** | High |
| **Dependencies** | Phase 2 |
| **Parallelizable** | Yes (with Phase 3a, 3b, Phase 4) |

**Objective:** Implement complex host TTS providers including Windows SAPI and neural TTS engines.

**Providers (3):**
- `SAPI` (Windows) - Windows Speech API via PowerShell
- `KokoroTts` - Kokoro neural TTS with model/voice selection
- `Mimic3` - Mycroft neural TTS with SSML support

**Deliverables:**
- `providers/host/sapi.rs` - Windows SAPI via PowerShell implementation
- `providers/host/kokoro.rs` - Kokoro TTS implementation
- `providers/host/mimic3.rs` - Mimic3 implementation

**Windows SAPI Implementation (PowerShell approach):**
```rust
// providers/host/sapi.rs
#[cfg(target_os = "windows")]
pub async fn speak(&self, text: &str, config: &TtsConfig) -> Result<(), TtsError> {
    // Use PowerShell with Add-Type for SAPI access
    let escaped_text = text.replace("'", "''");
    let script = format!(
        r#"
        Add-Type -AssemblyName System.Speech
        $synth = New-Object System.Speech.Synthesis.SpeechSynthesizer
        {}
        $synth.Speak('{}')
        "#,
        config.requested_voice
            .as_ref()
            .map(|v| format!("$synth.SelectVoice('{}')", v))
            .unwrap_or_default(),
        escaped_text
    );

    let mut cmd = tokio::process::Command::new("powershell");
    cmd.args(["-NoProfile", "-NonInteractive", "-Command", &script]);

    let output = cmd.output().await?;
    // ... handle output
}
```

**Acceptance Criteria:**
- [ ] SAPI works on Windows via PowerShell (no COM interop complexity)
- [ ] KokoroTts supports voice blending syntax (e.g., `af_sarah:60,am_adam:40`)
- [ ] Mimic3 supports SSML input when available
- [ ] All providers have proper `#[cfg(target_os = "...")]` guards
- [ ] Unit tests for each provider

---

### Phase 4: ElevenLabs Cloud TTS Implementation

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio, reqwest |
| **Suggested Skills** | serde (for response parsing) |
| **Complexity** | Medium |
| **Dependencies** | Phase 2 |
| **Parallelizable** | Yes (with Phase 3a, 3b, 3c) |

**Objective:** Implement ElevenLabs cloud TTS using schematic-schema generated client.

**Deliverables:**
- `providers/cloud/elevenlabs.rs` - ElevenLabs TTS implementation
- `providers/cloud/mod.rs` - Cloud provider module
- Voice listing and caching functionality
- Audio format handling (MP3 default, with PCM option)

**Key Implementation with Error Handling Fix:**
```rust
// providers/cloud/elevenlabs.rs
use schematic_schema::elevenlabs::{CreateSpeechRequest, CreateSpeechBody};

pub struct ElevenLabsProvider {
    api_key: String,
    client: reqwest::Client,
    default_voice_id: String,
}

impl ElevenLabsProvider {
    pub fn new() -> Result<Self, TtsError> {
        let api_key = std::env::var("ELEVENLABS_API_KEY")
            .or_else(|_| std::env::var("ELEVEN_LABS_API_KEY"))
            .map_err(|_| TtsError::MissingApiKey {
                provider: "elevenlabs".into()
            })?;

        Ok(Self {
            api_key,
            client: reqwest::Client::new(),
            default_voice_id: "21m00Tcm4TlvDq8ikWAM".into(), // Rachel
        })
    }

    pub async fn speak(&self, text: &str, config: &TtsConfig) -> Result<(), TtsError> {
        let voice_id = config.requested_voice
            .as_ref()
            .unwrap_or(&self.default_voice_id);

        let body = CreateSpeechBody {
            text: text.to_string(),
            model_id: Some("eleven_multilingual_v2".into()),
            ..Default::default()
        };

        let request = CreateSpeechRequest::new(voice_id.clone(), body);

        // CORRECT: Use ? operator, not unwrap()
        let (method, path, body_json, headers) = request.into_parts()?;

        let url = format!("https://api.elevenlabs.io{}", path);

        let mut req = self.client
            .request(reqwest::Method::from_bytes(method.as_bytes())?, &url)
            .header("xi-api-key", &self.api_key)
            .header("Content-Type", "application/json");

        if let Some(json) = body_json {
            req = req.body(json);
        }

        let response = req.send().await?;

        if !response.status().is_success() {
            let status = response.status();
            let error_body = response.text().await.unwrap_or_default();
            return Err(TtsError::ApiError {
                provider: "elevenlabs".into(),
                status: status.as_u16(),
                message: error_body,
            });
        }

        // Binary audio response
        let audio_bytes = response.bytes().await?;

        // Play audio (delegates to playback module)
        crate::playback::play_audio_bytes(&audio_bytes, AudioFormat::Mp3).await
    }
}
```

**Acceptance Criteria:**
- [ ] ElevenLabs provider implements `TtsExecutor` trait
- [ ] API key checked from both `ELEVENLABS_API_KEY` and `ELEVEN_LABS_API_KEY`
- [ ] Binary response correctly handled as `Vec<u8>` audio data
- [ ] No `unwrap()` on fallible operations (use `?` operator)
- [ ] Voice listing endpoint integrated for voice discovery
- [ ] Unit tests with mocked HTTP responses (wiremock)

---

### Phase 5: Speak Struct & Builder API

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio |
| **Suggested Skills** | thiserror (for error context) |
| **Complexity** | Medium |
| **Dependencies** | Phase 3a, 3b, 3c, Phase 4 |
| **Parallelizable** | No (integrates all providers) |

**Objective:** Implement the main `Speak` struct with builder pattern and auto-failover support.

**Deliverables:**
- Complete `Speak` struct implementation in `speak.rs`
- Builder pattern methods for all configuration options
- `prepare()` method for pre-generating audio
- `play()` method for async playback
- `speak()` convenience function (non-struct API)
- `speak_when_able()` fire-and-forget variant
- Auto-failover logic with comprehensive error collection

**API Design:**
```rust
// speak.rs
pub struct Speak {
    text: String,
    audio: Option<Vec<u8>>,
    config: TtsConfig,
    failover_strategy: TtsFailoverStrategy,
}

impl Speak {
    pub fn new(text: impl Into<String>) -> Self {
        Self {
            text: text.into(),
            audio: None,
            config: TtsConfig::default(),
            failover_strategy: TtsFailoverStrategy::default(),
        }
    }

    /// Pre-generate audio (useful for latency-sensitive scenarios)
    pub async fn prepare(mut self) -> Result<Self, TtsError> {
        let providers = get_available_providers();
        let audio = self.generate_audio(providers).await?;
        self.audio = Some(audio);
        Ok(self)
    }

    /// Play the audio (generates if not prepared)
    pub async fn play(self) -> Result<(), TtsError> {
        if let Some(audio) = self.audio {
            crate::playback::play_audio_bytes(&audio, AudioFormat::Wav).await
        } else {
            let providers = get_available_providers();
            self.execute_with_failover(providers).await
        }
    }

    /// Execute with failover, collecting ALL errors
    async fn execute_with_failover(&self, providers: &[TtsProvider]) -> Result<(), TtsError> {
        let mut errors: Vec<(TtsProvider, TtsError)> = Vec::new();

        for provider in providers {
            match self.execute_provider(provider).await {
                Ok(()) => return Ok(()),
                Err(e) => {
                    tracing::debug!(provider = ?provider, error = ?e, "Provider failed, trying next");
                    errors.push((provider.clone(), e));
                }
            }
        }

        // All providers failed - return ALL errors for debugging
        Err(TtsError::AllProvidersFailed(AllProvidersFailed { errors }))
    }

    // Builder methods
    pub fn with_voice(mut self, voice: impl Into<String>) -> Self {
        self.config.requested_voice = Some(voice.into());
        self
    }

    pub fn with_gender(mut self, gender: Gender) -> Self {
        self.config.gender = gender;
        self
    }

    pub fn with_language(mut self, lang: Language) -> Self {
        self.config.language = lang;
        self
    }

    pub fn with_failover(mut self, strategy: TtsFailoverStrategy) -> Self {
        self.failover_strategy = strategy;
        self
    }
}

/// Convenience function for simple TTS
pub async fn speak(text: &str, config: &TtsConfig) -> Result<(), TtsError> {
    Speak::new(text)
        .with_config(config.clone())
        .play()
        .await
}

/// Fire-and-forget TTS (logs errors but doesn't propagate)
pub async fn speak_when_able(text: &str, config: &TtsConfig) {
    if let Err(e) = speak(text, config).await {
        tracing::debug!(error = ?e, "TTS failed (non-fatal)");
    }
}
```

**Acceptance Criteria:**
- [ ] `Speak::new()` creates instance with defaults
- [ ] All builder methods return `Self` for chaining
- [ ] `prepare()` pre-generates audio for later playback
- [ ] `play()` generates on-demand if not prepared
- [ ] Failover collects ALL errors in `Vec<(TtsProvider, TtsError)>`
- [ ] `speak()` and `speak_when_able()` convenience functions work
- [ ] Unit tests for builder pattern and failover logic

---

### Phase 6: Audio Playback Utilities

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio |
| **Suggested Skills** | None |
| **Complexity** | Low |
| **Dependencies** | Phase 1 |
| **Parallelizable** | Yes (with Phase 2) |

**Objective:** Implement cross-platform audio playback for generated TTS audio.

**Deliverables:**
- `playback/mod.rs` - Audio playback module
- `play_audio_bytes()` function for in-memory audio
- `play_audio_file()` function for file-based audio
- OS-specific player detection (afplay, aplay, paplay, etc.)
- Temporary file management with automatic cleanup

**Implementation (NOT async for get_audio_player):**
```rust
// playback/mod.rs
use std::path::Path;
use tempfile::NamedTempFile;

/// Audio players by platform preference
#[cfg(target_os = "macos")]
const AUDIO_PLAYERS: &[&str] = &["afplay"];

#[cfg(target_os = "linux")]
const AUDIO_PLAYERS: &[&str] = &["paplay", "aplay", "play"];

#[cfg(target_os = "windows")]
const AUDIO_PLAYERS: &[&str] = &["powershell"]; // Uses media player cmdlet

/// Get the first available audio player - NOT async (no I/O needed)
pub fn get_audio_player() -> Option<&'static str> {
    for player in AUDIO_PLAYERS {
        if which::which(player).is_ok() {
            return Some(player);
        }
    }
    None
}

/// Play audio bytes by writing to temp file and invoking player
pub async fn play_audio_bytes(data: &[u8], format: AudioFormat) -> Result<(), TtsError> {
    let extension = match format {
        AudioFormat::Wav => "wav",
        AudioFormat::Mp3 => "mp3",
        AudioFormat::Pcm => "raw",
    };

    // Create temp file (automatically cleaned up on drop)
    let temp_file = NamedTempFile::with_suffix(&format!(".{}", extension))
        .map_err(|e| TtsError::TempFileError { source: e })?;

    tokio::fs::write(temp_file.path(), data).await?;

    play_audio_file(temp_file.path()).await
}

/// Play audio file using system player
pub async fn play_audio_file(path: &Path) -> Result<(), TtsError> {
    let player = get_audio_player()
        .ok_or(TtsError::NoAudioPlayer)?;

    #[cfg(target_os = "windows")]
    let args = vec![
        "-NoProfile".to_string(),
        "-Command".to_string(),
        format!(
            "(New-Object Media.SoundPlayer '{}').PlaySync()",
            path.display()
        ),
    ];

    #[cfg(not(target_os = "windows"))]
    let args = vec![path.to_string_lossy().to_string()];

    let output = tokio::process::Command::new(player)
        .args(&args)
        .output()
        .await?;

    if !output.status.success() {
        return Err(TtsError::PlaybackFailed {
            player: player.to_string(),
            stderr: String::from_utf8_lossy(&output.stderr).to_string(),
        });
    }

    Ok(())
}
```

**Acceptance Criteria:**
- [ ] `get_audio_player()` is NOT async (simple path check)
- [ ] Temp files cleaned up automatically via `NamedTempFile`
- [ ] All three platforms supported (macOS, Linux, Windows)
- [ ] Audio format extension matches actual format
- [ ] Unit tests for player detection

---

### Phase 7a: Update so-you-say Client

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, clap |
| **Suggested Skills** | tokio (for async main) |
| **Complexity** | Medium |
| **Dependencies** | Phase 5 |
| **Parallelizable** | Yes (with Phase 7b, 7c) |

**Objective:** Update so-you-say CLI to use the new async biscuit-speaks API.

**Deliverables:**
- Updated `so-you-say/src/main.rs` with async main
- Migration from `speak_when_able()` blocking to async
- Add `--provider` flag for explicit provider selection
- Add `--list-providers` flag to show available TTS providers

**Key Changes:**
```rust
// so-you-say/src/main.rs
use biscuit_speaks::{Speak, TtsConfig, TtsFailoverStrategy, speak_when_able};

#[derive(Parser)]
struct Cli {
    // ... existing flags ...

    /// Use a specific TTS provider
    #[arg(long)]
    provider: Option<String>,

    /// List available TTS providers
    #[arg(long)]
    list_providers: bool,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();

    if cli.list_providers {
        let providers = biscuit_speaks::get_available_providers();
        for p in providers {
            println!("{:?}", p);
        }
        return Ok(());
    }

    // ... existing voice list and text handling ...

    // Build Speak instance
    let mut speak = Speak::new(&message);

    if let Some(voice_name) = &cli.voice {
        speak = speak.with_voice(voice_name);
    }

    if let Some(gender) = cli.gender {
        speak = speak.with_gender(gender.into());
    }

    if let Some(provider) = &cli.provider {
        // Parse provider and set specific provider strategy
        let p = provider.parse::<TtsProvider>()?;
        speak = speak.with_failover(TtsFailoverStrategy::SpecificProvider(p));
    }

    speak.play().await?;

    Ok(())
}
```

**Acceptance Criteria:**
- [ ] `#[tokio::main]` attribute on main function
- [ ] `--provider` flag works with all supported providers
- [ ] `--list-providers` shows detected providers
- [ ] Existing `--voice` and `--gender` flags still work
- [ ] `--list-voices` still works (queries provider for voices)
- [ ] CLI tests pass

---

### Phase 7b: Update research/lib Client

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio |
| **Suggested Skills** | None |
| **Complexity** | Low |
| **Dependencies** | Phase 5 |
| **Parallelizable** | Yes (with Phase 7a, 7c) |

**Objective:** Update research library to use async TTS if it has internal TTS calls.

**Deliverables:**
- Audit research/lib for any direct TTS usage
- Update any internal TTS calls to async API
- Ensure TTS is only used in appropriate async contexts

**Note:** Based on grep results, research/lib does NOT directly use TTS - usage is in research/cli only. This phase may be a no-op but verify during implementation.

**Acceptance Criteria:**
- [ ] Audit confirms no TTS usage in research/lib (or updates if found)
- [ ] `cargo build -p research-lib` compiles
- [ ] `cargo test -p research-lib` passes

---

### Phase 7c: Update research/cli Client

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust, tokio, clap |
| **Suggested Skills** | color-eyre (for error context) |
| **Complexity** | Medium |
| **Dependencies** | Phase 5 |
| **Parallelizable** | Yes (with Phase 7a, 7b) |

**Objective:** Update research CLI to use async TTS for completion announcements.

**Current Usage (from grep):**
```rust
// research/cli/src/main.rs:265
use biscuit_speaks::{VoiceConfig, speak_when_able};
speak_when_able(&message, &VoiceConfig::default());

// research/cli/src/main.rs:348
use biscuit_speaks::{VoiceConfig, speak_when_able};
speak_when_able(&message, &VoiceConfig::default());
```

**Updated Usage:**
```rust
// research/cli/src/main.rs
use biscuit_speaks::{TtsConfig, speak_when_able};

// Inside async context:
speak_when_able(&message, &TtsConfig::default()).await;
```

**Acceptance Criteria:**
- [ ] Both TTS call sites updated to async
- [ ] Import changed from `VoiceConfig` to `TtsConfig`
- [ ] TTS still fires on research completion
- [ ] TTS failure does not crash research CLI
- [ ] `cargo build -p research-cli` compiles
- [ ] Manual test of research completion announcement

---

### Phase 8: Remove tts Crate & Cleanup

| Property | Value |
|----------|-------|
| **Subagent** | `general-purpose` |
| **Required Skills** | rust |
| **Suggested Skills** | None |
| **Complexity** | Low |
| **Dependencies** | Phase 7a, 7b, 7c |
| **Parallelizable** | Yes (with Phase 9a) |

**Objective:** Remove the `tts` crate dependency and clean up legacy code.

**Deliverables:**
- Remove `tts` from `biscuit-speaks/Cargo.toml`
- Delete `biscuit-speaks/src/old.rs`
- Update `lib.rs` to remove old module references
- Clean up any remaining `tts` crate types (e.g., `tts::Gender`, `tts::Voice`)
- Ensure all re-exports use new types

**Checklist:**
- [ ] `tts` removed from dependencies
- [ ] `old.rs` deleted
- [ ] No references to `tts::` types remain
- [ ] `cargo build -p biscuit-speaks` compiles
- [ ] `cargo build --workspace` compiles
- [ ] No clippy warnings from removed code

**Acceptance Criteria:**
- [ ] `tts` crate no longer in dependency tree
- [ ] All workspace packages build successfully
- [ ] No dead code warnings

---

### Phase 9a: Unit Testing

| Property | Value |
|----------|-------|
| **Subagent** | `feature-tester-rust` |
| **Required Skills** | rust, rust-testing |
| **Suggested Skills** | wiremock (for HTTP mocking), tokio (for async tests) |
| **Complexity** | Medium |
| **Dependencies** | Phase 8 |
| **Parallelizable** | Yes (with Phase 8) |

**Objective:** Comprehensive unit test coverage for all new TTS components.

**Test Categories:**

1. **Type Tests** (`types.rs`)
   - `TtsConfig` builder pattern
   - `TtsFailoverStrategy` variants
   - `AudioFormat` conversions

2. **Detection Tests** (`detection.rs`)
   - Provider detection with mocked sniff-lib
   - Stack building for each OS
   - Environment variable overrides

3. **Provider Tests** (`providers/`)
   - Each host provider with mocked process execution
   - ElevenLabs with wiremock HTTP mocking
   - Error handling for each failure mode

4. **Speak Tests** (`speak.rs`)
   - Builder pattern chaining
   - Failover logic with mock providers
   - Error accumulation

5. **Playback Tests** (`playback/`)
   - Player detection
   - Temp file creation/cleanup

**Test Patterns:**
```rust
#[cfg(test)]
mod tests {
    use super::*;
    use wiremock::{MockServer, Mock, ResponseTemplate};
    use wiremock::matchers::{method, path};

    #[tokio::test]
    async fn test_elevenlabs_success() {
        let mock_server = MockServer::start().await;

        Mock::given(method("POST"))
            .and(path("/v1/text-to-speech/test-voice"))
            .respond_with(
                ResponseTemplate::new(200)
                    .set_body_bytes(include_bytes!("../fixtures/test.mp3"))
            )
            .mount(&mock_server)
            .await;

        // Test with mock server URL
    }

    #[tokio::test]
    async fn test_failover_collects_all_errors() {
        let speak = Speak::new("test");
        // Configure with mock providers that all fail
        let result = speak.play().await;

        match result {
            Err(TtsError::AllProvidersFailed(e)) => {
                assert_eq!(e.errors.len(), 3); // All providers attempted
            }
            _ => panic!("Expected AllProvidersFailed error"),
        }
    }
}
```

**Acceptance Criteria:**
- [ ] >80% code coverage for biscuit-speaks
- [ ] All error paths tested
- [ ] Async tests use `#[tokio::test]`
- [ ] HTTP tests use wiremock
- [ ] `cargo test -p biscuit-speaks` passes

---

### Phase 9b: Integration Testing

| Property | Value |
|----------|-------|
| **Subagent** | `feature-tester-rust` |
| **Required Skills** | rust, rust-testing |
| **Suggested Skills** | tokio (for async tests) |
| **Complexity** | Medium |
| **Dependencies** | Phase 9a |
| **Parallelizable** | No (final validation) |

**Objective:** End-to-end integration tests verifying actual TTS functionality.

**Integration Test Categories:**

1. **CLI Integration** (`so-you-say`)
   - `--list-voices` output format
   - `--list-providers` output format
   - Basic speech with default provider
   - Provider selection via `--provider`

2. **Provider Integration** (conditional on availability)
   - Skip if provider not installed
   - Actual TTS output (may need audio capture or just success/failure)

3. **Failover Integration**
   - Test with intentionally broken first provider
   - Verify second provider succeeds

**Test Patterns:**
```rust
// tests/integration/cli_test.rs
use assert_cmd::Command;

#[test]
fn test_list_providers_output() {
    let mut cmd = Command::cargo_bin("speak").unwrap();
    cmd.arg("--list-providers")
        .assert()
        .success()
        .stdout(predicates::str::contains("Say").or(
            predicates::str::contains("ESpeak")
        ));
}

#[test]
#[ignore] // Run manually - produces audio
fn test_actual_speech() {
    let mut cmd = Command::cargo_bin("speak").unwrap();
    cmd.arg("Integration test")
        .assert()
        .success();
}
```

**Acceptance Criteria:**
- [ ] CLI integration tests pass
- [ ] At least one provider works on CI (use Say on macOS runners)
- [ ] `cargo test --workspace` passes
- [ ] Manual verification of actual audio output

---

## Lessons Learned

> Capture discoveries about skills or memory resources (CLAUDE.md, README.md, etc.) that were inaccurate, incomplete, or missing. These insights help improve future planning sessions.

- [CRATE: tts]: The tts crate provides native bindings but has platform-specific compilation challenges; CLI-based approach offers more flexibility
- [API: schematic-schema]: Generated API clients provide `into_parts()` method returning tuple of (method, path, body, headers) - useful for custom HTTP execution
- [CODE: biscuit-speaks/old.rs]: Functions `speak_when_able()` and `available_system_voices()` defined here but not re-exported from lib.rs - potential broken state
- [CODE: biscuit-speaks/types.rs]: `HostTtsProvider::is_available()` at line 204 contains only `todo!()` - blocker for provider selection
- [API: macOS say]: The `-v` flag selects VOICE (e.g., `-v Alex`), NOT volume. macOS `say` has no direct volume flag
- [PATTERN: stdin EOF]: Process stdin must be explicitly closed (dropped) to send EOF signal; omission causes hangs
- [PATTERN: error accumulation]: Collecting only last_error loses debug info; should collect all failures in Vec
- [DEPENDENCY: futures]: May be needed for concurrent task coordination in Phase 3/4 parallel execution


## Package Changes in Execution

> Dependencies to be added, updated, or removed during implementation. Research for ADD actions produces skill files.

- [ADD(biscuit-speaks)]: schematic-schema in cargo - ElevenLabs cloud TTS API client
    - "How does schematic-schema handle binary response bodies for audio streaming?"
- [ADD(biscuit-speaks)]: tokio in cargo - Async runtime for process spawning and HTTP requests
    - "What tokio features are needed for async Command execution?"
- [ADD(biscuit-speaks)]: async-trait in cargo - Async trait support for TtsExecutor trait
    - "Is async-trait still necessary with Rust 2024 edition async trait support?"
- [ADD(biscuit-speaks)]: tempfile in cargo - Temporary file management for audio playback
    - "Does tempfile automatically clean up on drop in async contexts?"
- [ADD(biscuit-speaks)]: reqwest in cargo - HTTP client for ElevenLabs API
    - "What features needed: json, stream?"
- [ADD(biscuit-speaks)]: futures in cargo - Concurrent task coordination
- [ADD(biscuit-speaks)]: which in cargo - Cross-platform executable detection for audio players
- [ADD(biscuit-speaks)]: wiremock in cargo (dev) - HTTP mocking for ElevenLabs tests
- [REMOVE(biscuit-speaks)]: tts in cargo - Replaced by CLI-based host TTS and cloud TTS
- [DO_NOT_ADD]: async-trait - May not be needed with Rust 2024 edition native async traits

---

## Final Plan Summary

### Phase Overview

| Phase | Name | Complexity | Dependencies | Parallelizable With |
|-------|------|------------|--------------|---------------------|
| 0 | Pre-Implementation Validation | Low | None | None |
| 1 | Core Type Definitions | Medium | Phase 0 | None |
| 2 | TTS Provider Detection | Medium | Phase 1 | Phase 6 |
| 3a | Simple Host TTS Providers | Medium | Phase 2 | Phase 3b, 3c, 4 |
| 3b | Medium Host TTS Providers | Medium | Phase 2 | Phase 3a, 3c, 4 |
| 3c | Complex Host TTS Providers | High | Phase 2 | Phase 3a, 3b, 4 |
| 4 | ElevenLabs Cloud TTS | Medium | Phase 2 | Phase 3a, 3b, 3c |
| 5 | Speak Struct & Builder API | Medium | Phase 3a-c, 4 | None |
| 6 | Audio Playback Utilities | Low | Phase 1 | Phase 2 |
| 7a | Update so-you-say | Medium | Phase 5 | Phase 7b, 7c |
| 7b | Update research/lib | Low | Phase 5 | Phase 7a, 7c |
| 7c | Update research/cli | Medium | Phase 5 | Phase 7a, 7b |
| 8 | Remove tts Crate | Low | Phase 7a-c | Phase 9a |
| 9a | Unit Testing | Medium | Phase 8 | Phase 8 |
| 9b | Integration Testing | Medium | Phase 9a | None |

### Critical Code Fixes Applied

1. **macOS say -v flag**: Changed from volume to voice selection (macOS has no volume flag)
2. **stdin EOF signal**: Added explicit `drop(stdin)` after writing to child process
3. **Error accumulation**: Changed from `last_error` to `Vec<(TtsProvider, TtsError)>`
4. **get_audio_player()**: Changed from async to sync (no I/O needed)
5. **ElevenLabs error handling**: Changed from `unwrap()` to `?` operator

### Estimated Timeline

- **Sequential execution**: 35-45 hours
- **Optimized parallel execution**: 18-24 hours (40-50% reduction)

### Skills Required Across All Phases

**Required**: rust, tokio, thiserror, strum
**Suggested**: reqwest, serde, clap, wiremock, rust-testing

